{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2f932f-12cc-49c7-8205-5470ae994106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject  Test1  Test2  Test3  Test4\n",
      "0  Subject 1     80     75     88     90\n",
      "1  Subject 2     85     80     84     87\n",
      "2  Subject 3     78     82     86     85\n",
      "3  Subject 4     90     85     92     88\n",
      "4  Subject 5     88     89     91     93\n",
      "     Subject  Test1  Test2  Test3  Test4\n",
      "0  Subject 1     80     75     88     90\n",
      "1  Subject 2     85     80     84     87\n",
      "2  Subject 3     78     82     86     85\n",
      "3  Subject 4     90     85     92     88\n",
      "4  Subject 5     88     89     91     93\n",
      "     Subject Test1 Test2 Test3 Test4\n",
      "0  Subject 1    80    75    88    90\n",
      "1  Subject 2    85    80    84    87\n",
      "2  Subject 3    78    82    86    85\n",
      "3  Subject 4    90    85    92    88\n",
      "4  Subject 5    88    89    91    93\n",
      "     Subject  Test1  Test2  Test3  Test4\n",
      "0  Subject 1     80     75     88     90\n",
      "1  Subject 2     85     80     84     87\n",
      "2  Subject 3     78     82     86     85\n",
      "3  Subject 4     90     85     92     88\n",
      "4  Subject 5     88     89     91     93\n"
     ]
    }
   ],
   "source": [
    "#assignment1\n",
    "#create a dataframe called Student Assesstment test  marks containing 4 assessment test marks in 5 subjects . Perform add a new row\n",
    "#called subject 6 add new column mid1,mid2,mid3 and lab. Rename mid1,mid2,mid3 to MD1,MD2,MD3 .DElete lab marks from the dataframe.\n",
    "#Display all the above created dataframe. Create dataframe using all 4 methods\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Method 1: Creating DataFrame using Dictionary\n",
    "data_dict = {\n",
    "    'Subject': ['Subject 1', 'Subject 2', 'Subject 3', 'Subject 4', 'Subject 5'],\n",
    "    'Test1': [80, 85, 78, 90, 88],\n",
    "    'Test2': [75, 80, 82, 85, 89],\n",
    "    'Test3': [88, 84, 86, 92, 91],\n",
    "    'Test4': [90, 87, 85, 88, 93]\n",
    "}\n",
    "df_dict = pd.DataFrame(data_dict)\n",
    "print(df_dict)\n",
    "# Method 2: Creating DataFrame using Lists\n",
    "data_list = [\n",
    "    ['Subject 1', 80, 75, 88, 90],\n",
    "    ['Subject 2', 85, 80, 84, 87],\n",
    "    ['Subject 3', 78, 82, 86, 85],\n",
    "    ['Subject 4', 90, 85, 92, 88],\n",
    "    ['Subject 5', 88, 89, 91, 93]\n",
    "]\n",
    "columns_list = ['Subject', 'Test1', 'Test2', 'Test3', 'Test4']\n",
    "df_list = pd.DataFrame(data_list, columns=columns_list)\n",
    "print(df_list)\n",
    "\n",
    "# Method 3: Creating DataFrame using NumPy Arrays\n",
    "data_array = np.array([\n",
    "    ['Subject 1', 80, 75, 88, 90],\n",
    "    ['Subject 2', 85, 80, 84, 87],\n",
    "    ['Subject 3', 78, 82, 86, 85],\n",
    "    ['Subject 4', 90, 85, 92, 88],\n",
    "    ['Subject 5', 88, 89, 91, 93]\n",
    "])\n",
    "df_array = pd.DataFrame(data_array, columns=columns_list)\n",
    "print(df_array)\n",
    "# Method 4: Creating DataFrame using from_records()\n",
    "data_records = [\n",
    "    ('Subject 1', 80, 75, 88, 90),\n",
    "    ('Subject 2', 85, 80, 84, 87),\n",
    "    ('Subject 3', 78, 82, 86, 85),\n",
    "    ('Subject 4', 90, 85, 92, 88),\n",
    "    ('Subject 5', 88, 89, 91, 93)\n",
    "]\n",
    "df_records = pd.DataFrame.from_records(data_records, columns=columns_list)\n",
    "print(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17845fe4-b84e-4b3a-8dec-5ab12742cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject  Test1  Test2  Test3  Test4\n",
      "0  Subject 1     80     75     88     90\n",
      "1  Subject 2     85     80     84     87\n",
      "2  Subject 3     78     82     86     85\n",
      "3  Subject 4     90     85     92     88\n",
      "4  Subject 5     88     89     91     93\n",
      "5  Subject 6     85     88     87     90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Add a new row (Subject 6)\n",
    "df = df_dict.copy()\n",
    "df.loc[5] = ['Subject 6', 85, 88, 87, 90]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86aa0af2-aaae-4e20-8537-96f6646f6f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject  Test1  Test2  Test3  Test4  Mid1  Mid2  Mid3  Lab\n",
      "0  Subject 1     80     75     88     90    80    80    80   80\n",
      "1  Subject 2     85     80     84     87    85    85    85   85\n",
      "2  Subject 3     78     82     86     85    78    78    78   78\n",
      "3  Subject 4     90     85     92     88    90    90    90   90\n",
      "4  Subject 5     88     89     91     93    88    88    88   88\n",
      "5  Subject 6     85     88     87     90    82    82    82   82\n",
      "     Subject  Test1  Test2  Test3  Test4  MD1  MD2  MD3  Lab\n",
      "0  Subject 1     80     75     88     90   80   80   80   80\n",
      "1  Subject 2     85     80     84     87   85   85   85   85\n",
      "2  Subject 3     78     82     86     85   78   78   78   78\n",
      "3  Subject 4     90     85     92     88   90   90   90   90\n",
      "4  Subject 5     88     89     91     93   88   88   88   88\n",
      "5  Subject 6     85     88     87     90   82   82   82   82\n"
     ]
    }
   ],
   "source": [
    "# Add new columns\n",
    "for col in ['Mid1', 'Mid2', 'Mid3', 'Lab']:\n",
    "     df[col] = [80, 85, 78, 90, 88, 82]\n",
    "print(df)\n",
    "# Rename columns Mid1, Mid2, Mid3\n",
    "rename_dict = {'Mid1': 'MD1', 'Mid2': 'MD2', 'Mid3': 'MD3'}\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1debff31-2e15-47fe-9080-139dc6889837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame:\n",
      "     Subject  Test1  Test2  Test3  Test4  MD1  MD2  MD3\n",
      "0  Subject 1     80     75     88     90   80   80   80\n",
      "1  Subject 2     85     80     84     87   85   85   85\n",
      "2  Subject 3     78     82     86     85   78   78   78\n",
      "3  Subject 4     90     85     92     88   90   90   90\n",
      "4  Subject 5     88     89     91     93   88   88   88\n",
      "5  Subject 6     85     88     87     90   82   82   82\n"
     ]
    }
   ],
   "source": [
    "# Delete Lab marks\n",
    "df.drop(columns=['Lab'], inplace=True)\n",
    "# Display the final DataFrame\n",
    "print(\"Final DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27911058-970d-42b5-80da-2d627d418fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marks    85\n",
      "Name: Internal, dtype: int64\n",
      "Marks    90\n",
      "Name: External, dtype: int64\n",
      "Sum of Marks: Marks    175\n",
      "dtype: int64\n",
      "Difference of Marks: Marks   -5\n",
      "dtype: int64\n",
      "Product of Marks: Marks    7650\n",
      "dtype: int64\n",
      "Division of Marks: Marks    0.944444\n",
      "dtype: float64\n",
      "Internal Marks: 85\n",
      "Part of External Marks: Marks    90\n",
      "Name: External, dtype: int64\n",
      "Attributes of External Series: ['Marks', 'T', '_AXIS_LEN', '_AXIS_ORDERS', '_AXIS_TO_AXIS_NUMBER', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__bool__', '__class__', '__column_consortium_standard__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pandas_priority__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_accum_func', '_agg_examples_doc', '_agg_see_also_doc', '_align_for_op', '_align_frame', '_align_series', '_append', '_arith_method', '_as_manager', '_attrs', '_binop', '_can_hold_na', '_check_inplace_and_allows_duplicate_labels', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_cmp_method', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_result', '_constructor', '_constructor_expanddim', '_constructor_expanddim_from_mgr', '_constructor_from_mgr', '_data', '_deprecate_downcast', '_dir_additions', '_dir_deletions', '_drop_axis', '_drop_labels_or_levels', '_duplicated', '_find_valid_index', '_flags', '_flex_method', '_from_mgr', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cacher', '_get_cleaned_column_resolvers', '_get_index_resolvers', '_get_label_or_level_values', '_get_numeric_data', '_get_rows_with_mask', '_get_value', '_get_values_tuple', '_get_with', '_getitem_slice', '_gotitem', '_hidden_attrs', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_init_dict', '_init_mgr', '_inplace_method', '_internal_names', '_internal_names_set', '_is_cached', '_is_copy', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_view', '_is_view_after_cow_rules', '_item_cache', '_ixs', '_logical_func', '_logical_method', '_map_values', '_maybe_update_cacher', '_memory_usage', '_metadata', '_mgr', '_min_count_stat_function', '_name', '_needs_reindex_multi', '_pad_or_backfill', '_protect_consolidate', '_reduce', '_references', '_reindex_axes', '_reindex_indexer', '_reindex_multi', '_reindex_with_indexers', '_rename', '_replace_single', '_repr_data_resource_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_set_as_cached', '_set_axis', '_set_axis_name', '_set_axis_nocheck', '_set_is_copy', '_set_labels', '_set_name', '_set_value', '_set_values', '_set_with', '_set_with_engine', '_shift_with_freq', '_slice', '_stat_function', '_stat_function_ddof', '_take_with_is_copy', '_to_latex_via_styler', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'apply', 'argmax', 'argmin', 'argsort', 'array', 'asfreq', 'asof', 'astype', 'at', 'at_time', 'attrs', 'autocorr', 'axes', 'backfill', 'between', 'between_time', 'bfill', 'bool', 'case_when', 'clip', 'combine', 'combine_first', 'compare', 'convert_dtypes', 'copy', 'corr', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'divmod', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtype', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'ewm', 'expanding', 'explode', 'factorize', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'ge', 'get', 'groupby', 'gt', 'hasnans', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'interpolate', 'is_monotonic_decreasing', 'is_monotonic_increasing', 'is_unique', 'isin', 'isna', 'isnull', 'item', 'items', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'list', 'loc', 'lt', 'map', 'mask', 'max', 'mean', 'median', 'memory_usage', 'min', 'mod', 'mode', 'mul', 'multiply', 'name', 'nbytes', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pad', 'pct_change', 'pipe', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'radd', 'rank', 'ravel', 'rdiv', 'rdivmod', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'repeat', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'searchsorted', 'sem', 'set_axis', 'set_flags', 'shape', 'shift', 'size', 'skew', 'sort_index', 'sort_values', 'squeeze', 'std', 'struct', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_frame', 'to_hdf', 'to_json', 'to_latex', 'to_list', 'to_markdown', 'to_numpy', 'to_period', 'to_pickle', 'to_sql', 'to_string', 'to_timestamp', 'to_xarray', 'transform', 'transpose', 'truediv', 'truncate', 'tz_convert', 'tz_localize', 'unique', 'unstack', 'update', 'value_counts', 'values', 'var', 'view', 'where', 'xs']\n"
     ]
    }
   ],
   "source": [
    "#assignemnt 2\n",
    "#create a 2 series called internal and external (name attribute) and row labelled as marks and find all the mathematical operations \n",
    "#on internal and external marks. Access the internal marks and part of external marks using indexing ans slicing find all attributes \n",
    "#on external series .Create series using numpy arrays and dictionaries\n",
    "\n",
    "\n",
    "# Create Series for Internal and External Marks\n",
    "internal = pd.Series([85], index=['Marks'], name='Internal')\n",
    "external = pd.Series([90], index=['Marks'], name='External')\n",
    "print(internal)\n",
    "print(external)\n",
    "\n",
    "# Mathematical operations on Internal and External Marks\n",
    "sum_marks = internal + external\n",
    "diff_marks = internal - external\n",
    "prod_marks = internal * external\n",
    "div_marks = internal / external\n",
    "\n",
    "# Accessing Internal Marks\n",
    "internal_marks = internal['Marks']\n",
    "\n",
    "# Accessing part of External Marks using Indexing and Slicing\n",
    "external_marks_part = external[:1]\n",
    "\n",
    "# Finding all attributes of External Series\n",
    "external_attributes = dir(external)\n",
    "\n",
    "# Creating Series using NumPy Arrays and Dictionaries\n",
    "internal_np = pd.Series(np.array([85]), index=['Marks'], name='Internal')\n",
    "external_dict = pd.Series({'Marks': 90}, name='External')\n",
    "\n",
    "# Display results of operations\n",
    "print(\"Sum of Marks:\", sum_marks)\n",
    "print(\"Difference of Marks:\", diff_marks)\n",
    "print(\"Product of Marks:\", prod_marks)\n",
    "print(\"Division of Marks:\", div_marks)\n",
    "print(\"Internal Marks:\", internal_marks)\n",
    "print(\"Part of External Marks:\", external_marks_part)\n",
    "print(\"Attributes of External Series:\", external_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c69dda4-59a9-4645-8ecb-a98d861267d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Subject  10th  P1  P2  E1  E2\n",
      "0       Math    95  80  75  88  90\n",
      "1    Science    88  85  80  84  87\n",
      "2    English    90  78  82  86  85\n",
      "3    History    85  90  85  92  88\n",
      "4  Geography    92  88  89  91  93\n",
      "     Subject  10th  P1  P2  E1  E2  Total  Average\n",
      "0       Math    95  80  75  88  90    333    83.25\n",
      "1    Science    88  85  80  84  87    336    84.00\n",
      "2    English    90  78  82  86  85    331    82.75\n",
      "3    History    85  90  85  92  88    355    88.75\n",
      "4  Geography    92  88  89  91  93    361    90.25\n",
      "Final DataFrame:\n",
      "     Subject  10th  P1  P2  E1  E2  Total  Average\n",
      "0       Math    95  80  75  88  90    333    83.25\n",
      "1    Science    88  85  80  84  87    336    84.00\n",
      "2    English    90  78  82  86  85    331    82.75\n",
      "3    History    85  90  85  92  88    355    88.75\n",
      "4  Geography    92  88  89  91  93    361    90.25\n"
     ]
    }
   ],
   "source": [
    "#assignment 3\n",
    "\n",
    "# Creating custom dataset\n",
    "data_custom = {\n",
    "    'Subject': ['Math', 'Science', 'English', 'History', 'Geography'],\n",
    "    '10th': [95, 88, 90, 85, 92],\n",
    "    'P1': [80, 85, 78, 90, 88],\n",
    "    'P2': [75, 80, 82, 85, 89],\n",
    "    'E1': [88, 84, 86, 92, 91],\n",
    "    'E2': [90, 87, 85, 88, 93]\n",
    "}\n",
    "df_custom = pd.DataFrame(data_custom)\n",
    "print(df_custom)\n",
    "# Performing manipulations\n",
    "df_custom['Total'] = df_custom[['P1', 'P2', 'E1', 'E2']].sum(axis=1)\n",
    "df_custom['Average'] = df_custom[['P1', 'P2', 'E1', 'E2']].mean(axis=1)\n",
    "\n",
    "print(df_custom)\n",
    "# Saving the dataset to an Excel file\n",
    "id_no = \"R210178\"  # Replace with actual ID\n",
    "file_name = f\"{id_no}.xlsx\"\n",
    "df_custom.to_excel(file_name, index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(\"Final DataFrame:\")\n",
    "print(df_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94441cbc-d8b2-47cf-93e1-b098f4dc6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#assignment 5\n",
    "#download one dataset from kagglewebsite , import , perform some manipulations and export the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download and import a dataset from Kaggle\n",
    "# Ensure you have the Kaggle API installed and configured\n",
    "# Example: !kaggle datasets download -d <dataset-name> -p <path>\n",
    "# Extract and load the dataset\n",
    "\n",
    "dataset_path = \"sample_dataset.csv\"  # Replace with the actual file name\n",
    "df_kaggle = pd.read_csv(dataset_path)\n",
    "\n",
    "# Performing manipulations\n",
    "df_kaggle.fillna(0, inplace=True)  # Replace missing values with 0\n",
    "df_kaggle['New_Column'] = df_kaggle.iloc[:, 1] * 2  # Example transformation\n",
    "\n",
    "# Saving the processed dataset\n",
    "output_file = \"processed_dataset.xlsx\"\n",
    "df_kaggle.to_excel(output_file, index=False)\n",
    "\n",
    "# Method 1: Creating DataFrame using Dictionary\n",
    "data_dict = {\n",
    "    'Subject': ['Subject 1', 'Subject 2', 'Subject 3', 'Subject 4', 'Subject 5'],\n",
    "    'Test1': [80, 85, 78, 90, 88],\n",
    "    'Test2': [75, 80, 82, 85, 89],\n",
    "    'Test3': [88, 84, 86, 92, 91],\n",
    "    'Test4': [90, 87, 85, 88, 93]\n",
    "}\n",
    "df_dict = pd.DataFrame(data_dict)\n",
    "\n",
    "# Method 2: Creating DataFrame using Lists\n",
    "data_list = [\n",
    "    ['Subject 1', 80, 75, 88, 90],\n",
    "    ['Subject 2', 85, 80, 84, 87],\n",
    "    ['Subject 3', 78, 82, 86, 85],\n",
    "    ['Subject 4', 90, 85, 92, 88],\n",
    "    ['Subject 5', 88, 89, 91, 93]\n",
    "]\n",
    "columns_list = ['Subject', 'Test1', 'Test2', 'Test3', 'Test4']\n",
    "df_list = pd.DataFrame(data_list, columns=columns_list)\n",
    "\n",
    "# Method 3: Creating DataFrame using NumPy Arrays\n",
    "data_array = np.array([\n",
    "    ['Subject 1', 80, 75, 88, 90],\n",
    "    ['Subject 2', 85, 80, 84, 87],\n",
    "    ['Subject 3', 78, 82, 86, 85],\n",
    "    ['Subject 4', 90, 85, 92, 88],\n",
    "    ['Subject 5', 88, 89, 91, 93]\n",
    "])\n",
    "df_array = pd.DataFrame(data_array, columns=columns_list)\n",
    "\n",
    "# Method 4: Creating DataFrame using from_records()\n",
    "data_records = [\n",
    "    ('Subject 1', 80, 75, 88, 90),\n",
    "    ('Subject 2', 85, 80, 84, 87),\n",
    "    ('Subject 3', 78, 82, 86, 85),\n",
    "    ('Subject 4', 90, 85, 92, 88),\n",
    "    ('Subject 5', 88, 89, 91, 93)\n",
    "]\n",
    "df_records = pd.DataFrame.from_records(data_records, columns=columns_list)\n",
    "\n",
    "# Creating custom dataset\n",
    "data_custom = {\n",
    "    'Subject': ['Math', 'Science', 'English', 'History', 'Geography'],\n",
    "    '10th': [95, 88, 90, 85, 92],\n",
    "    'P1': [80, 85, 78, 90, 88],\n",
    "    'P2': [75, 80, 82, 85, 89],\n",
    "    'E1': [88, 84, 86, 92, 91],\n",
    "    'E2': [90, 87, 85, 88, 93]\n",
    "}\n",
    "df_custom = pd.DataFrame(data_custom)\n",
    "\n",
    "# Performing manipulations\n",
    "df_custom['Total'] = df_custom[['P1', 'P2', 'E1', 'E2']].sum(axis=1)\n",
    "df_custom['Average'] = df_custom[['P1', 'P2', 'E1', 'E2']].mean(axis=1)\n",
    "\n",
    "# Saving the dataset to an Excel file\n",
    "id_no = \"12345\"  # Replace with actual ID\n",
    "file_name = f\"{id_no}.xlsx\"\n",
    "df_custom.to_excel(file_name, index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(\"Final DataFrame:\")\n",
    "print(df_custom)\n",
    "\n",
    "# Display processed Kaggle dataset\n",
    "print(\"Processed Kaggle Dataset:\")\n",
    "print(df_kaggle.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
